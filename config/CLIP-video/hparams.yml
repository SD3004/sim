# @Author: Simon Dahan @SD3004
# @Date:   31-08-2022 01:00:00

MODEL: clip-video
RECONSTRUCTION: False
distributed_training: True 
RESTART_TRAINING_ID: 0


##################################  DATA & TASK  ##################################

mesh_resolution:
  ico_mesh: 6 #resolution of the input mesh
  ico_grid: 4 #resolution of the grid used to extract patches
  sampling: msm #sampling used for mesh resampling and patch extraction #msm or wb ##
  reorder: False #reorder the sequence of patches ##

data:
  path_to_data: /drive/data
  path_to_template: ../data/templates
  path_to_workdir: ..
  dataset: HCP  #dHCP, HCP, UKB
  dataloader: bold #metrics, numpy, bold
  #task: movie  #movie, people, None ##
  #configuration: template #native, template ##
  masking: True # True to mask the cut.  
  hemi: half #half, full
  #hemi_part: all
  #demean: False
  normalise: None #standardise, standardise-vertex-wise,standardise-channel-wise,False, normalise, group-standardise,sub-standardise
  modality: tfMRI #cortical_metrics, fMRI, memory_task
  registration: msmall #msmsulc, msmall
  #clipping: True #True, False
  balance: False 
  subset: False
  single_subject: False  #100610, False
  train_val_split: split1 # split1 (subject split), split4 (all subjects)
  movie_sampling_strategy: any #any (sample anything from the subject), half (sample first half for training and second half for validation)


logging:
  folder_to_save_model: "{}/logs/{}/{}/CLIP/CLIP-video/SiT/ico_grid_{}/{}" #{dataset},{modality},{task},{grid resolution},{configuration}

###################################  MODEL  ####################################

transformer:
  dim: 192 #192, 384, 768, 96, 48
  depth: 12 #12, 12, 12
  heads: 3 #3, 6, 12
  mlp_ratio: 4 #mlp_dim: 768 #768, 1536, 3072 ## 4*dim according to DeiT
  pool: 'mean'  # 'cls' or 'mean'
  num_classes: 1
  #num_channels: 4 #cortical_metrics UKB/dHCP = 4; fMRI UKB = 490
  channels: [0]
  dim_head: 64 #64,32,16
  dropout: 0.0
  emb_dropout: 0.0
  use_bottleneck: False
  bottleneck_dropout: 0.0
  use_pos_embedding: 'sin-cos' #'trainable', 'sin-cos', False
  use_class_token: True #False
  trainable_pos_emb: False #False #only for use_pos_embedding=trainable
  no_class_token_emb: True #to use pos emb in the class token -> False, else True
  weights_layers_init: False #True -> layer weights
  init_weights: False #ssl, imagenet or False, ssl_svmae !!

video_model:
  video_name: 'videomae' #videomae
  video_loader: 'numpy' #numpy, video_encoder

clip:
  fmri_encoder: 'sit'
  video_encoder_trainable: False ##
  fmri_encoder_trainable: True
  clip_embedding_dimension: 384
  fmri_embedding_dims: 192
  video_embedding_dims: 768
  use_class_token_fmri_encoder: True ## not the same as the hparam in the transformer 
  dropout: 0.0
  temperature: 1.0
  clip_duration: 3
  avg_fmri: post_proj #prior_proj, post_proj
  concat_batches: True #True=concatenate batches, False=compute loss separately per GPU
  clip_loss_version: clip-openai #clip-v0, clip-openai

##################################  TRAINING  ###################################
  
training:
  LR: 0.0003
  bs: 4 #bs per gpu even for distributed
  bs_val: 4
  iterations: 100000
  log_val_it: 100
  gpu: 0
  loss: mse #mse, l1
  testing: False
  #testing_debug: False
  finetuning_fmri_model: True #ONLY for restart in runai cluster
  strict_weights: True 
  save_ckpt: True
  use_confounds: False
  use_cross_validation: True #True
  sampler: True 
  early_stopping: 30000
  cv_split: [1,2,3,4,5]
  runtime: False
  num_workers: 16 #bs 32 -> 16; then / 2
  
weights: 
  ssl_svmae: ''

augmentation: # prob of augmentation techniques need to sum to 1
  prob_augmentation: 0.0  #probability of using any of the augmentation technique; 0.0 to not use any augmentation
  prob_rotation: 0.5 #use rotation
  max_abs_deg_rotation: 15
  prob_warping: 0.5 #use non-linear warping
  prob_shuffle: 0.0 #use shuffling of patches
  warp_ico: 2

##################################  OPTIMISATION  ##################################
  
optimisation:
  optimiser: AdamW
  use_scheduler: False
  scheduler: CosineDecay  # CosineDecay, StepLR, ReduceLROnPlateau
  warmup: False
  nbr_step_warmup: 10
  momentum: 0.9 #default 0.
  nesterov: False

Adam:
  weight_decay: 0.01  #default 0.0, 0.01

AdamW:
  weight_decay: 0.01  #default 0.01
  
StepLR: 
  stepsize: 100
  decay: 0.1

CosineDecay:
  T_max: 50  # number of iteration to go from high to low
  eta_min: 0.00001  #minimum learning rate

fMRI:
  sampling_type: random #False, random, uniform, chunk
  nbr_frames: 3
  nbr_frames_ckpt: 3 # number of frames from the checkpoint
  window: 3
  average: False # True, False
  temporal_rep : channels #concat, avg, mix, tubelet
  temporal_lag: 6 # equivalent to starting sampling at t0+temporal_lag in seconds (typical peak of HRF at 4-6)
  #nbr_clip_sampled_fmri: 4 ### only used if RUNTIME=TRUE

##################################  OTHER  ##################################

ico_0_grid:
    num_patches: 20 
    num_vertices: 2145

ico_1_grid:
    num_patches: 80 
    num_vertices: 561 

ico_2_grid:
    num_patches: 320 
    num_vertices: 153 

ico_3_grid:
    num_patches: 1280
    num_vertices: 45
  
ico_4_grid:
    num_patches: 5120
    num_vertices: 15

ico_5_grid:
    num_patches: 20480
    num_vertices: 5